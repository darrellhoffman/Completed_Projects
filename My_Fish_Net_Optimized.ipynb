{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ECS695P - Neural Networks and Deep Learning\n",
        "## Coursework: Darrell Hoffman, 2022-04-22\n",
        "\n",
        "The purpose of this assignment was to build this specific NN architecture from our professor's description and then optimize the hyperparameters to obtain a validation accuracy of 90% on the MNIST dataset. I was one of 5% of students to receive a 100% grade on the assignment."
      ],
      "metadata": {
        "id": "AGckRgrXIUSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFabiz4mIZ6J"
      },
      "outputs": [],
      "source": [
        "#Connect to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')\n",
        "\n",
        "#Import Libraries\n",
        "import my_utils_edit as mu\n",
        "import torch\n",
        "from torch import nn\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataloader and Load Dataset "
      ],
      "metadata": {
        "id": "IWxBxziOIzql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "batch_size = 32\n",
        "train_iter, test_iter = mu.load_data_fashion_mnist(batch_size) # function defined in my_utils_edit.py edited from my_utils.py provided in week 3"
      ],
      "metadata": {
        "id": "NiMSdX4fIf_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Model"
      ],
      "metadata": {
        "id": "FGgJev35J-2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "random_flip = transforms.RandomHorizontalFlip(p=0.5)"
      ],
      "metadata": {
        "id": "Cu-hRT-NMsBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Model\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden, num_patches, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_patches = num_patches\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "        #Stem Linear Layers\n",
        "        self.LS1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.LS2 = nn.Linear(num_hidden, num_hidden)\n",
        "\n",
        "        #Stem Backbone Layers\n",
        "        self.LB1 = nn.Linear(num_patches, num_patches)\n",
        "        self.LB2 = nn.Linear(num_patches, num_patches)\n",
        "        self.LB3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.LB4 = nn.Linear(num_hidden, num_hidden)\n",
        "\n",
        "        self.LB5 = nn.Linear(num_patches, num_patches)\n",
        "        self.LB6 = nn.Linear(num_patches, num_patches)\n",
        "        self.LB7 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.LB8 = nn.Linear(num_hidden, num_hidden)\n",
        "\n",
        "        #Classifier Layers\n",
        "        self.LC1 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.LC2 = nn.Linear(num_hidden, num_outputs)\n",
        "\n",
        "        #Activation Function\n",
        "        self.relu = nn.LeakyReLU(0.1)\n",
        "\n",
        "        #Dropout Function\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #STEM\n",
        "        #Divide batch into patches\n",
        "        x = transforms.Lambda(lambda x: torch.stack([random_flip(x_) for x_ in x]))(x)\n",
        "        Img = torch.flatten(x, 1,2)\n",
        "\n",
        "        X_pij = Img.unfold(1,7,7).unfold(2,7,7)\n",
        "        X_pij = torch.flatten(X_pij, 1,2)\n",
        "\n",
        "        #Vectorize Patches\n",
        "        X_pij = torch.flatten(X_pij, 2,3)\n",
        "\n",
        "        #Transform to Feature Vector with MLP\n",
        "        X_xij = self.LS1(X_pij)\n",
        "        X_xij = self.relu(X_xij)\n",
        "        X_xij = self.LS2(X_xij)\n",
        "\n",
        "        #Block 1\n",
        "        #First B1 MLP\n",
        "        XT = torch.transpose(X_xij, 1, 2)\n",
        "        XW = self.LB1(XT)\n",
        "        XW_dropout = self.dropout(XW)\n",
        "        gXW = self.relu(XW_dropout)\n",
        "        O1 = self.LB2(gXW)\n",
        "        #Second B1 MLP\n",
        "        O1T = torch.transpose(O1, 1, 2)\n",
        "        O1W = self.LB3(O1T)\n",
        "        O1W_dropout = self.dropout(O1W)\n",
        "        gO1W = self.relu(O1W_dropout)\n",
        "        O2 = self.LB4(gO1W)\n",
        "\n",
        "        #Block 2\n",
        "        #First B2 MLP\n",
        "        O2T = torch.transpose(O2, 1, 2)\n",
        "        O2W = self.LB5(O2T)\n",
        "        O2W_dropout = self.dropout(O2W)\n",
        "        gO2W = self.relu(O2W_dropout)\n",
        "        O3 = self.LB6(gO2W)\n",
        "        #Second B2 MLP\n",
        "        O3T = torch.transpose(O1, 1, 2)\n",
        "        O3W = self.LB7(O3T)\n",
        "        O3W_dropout = self.dropout(O3W)\n",
        "        gO3W = self.relu(O3W_dropout)\n",
        "        O4 = self.LB8(gO3W)\n",
        "\n",
        "        #CLASSIFIER\n",
        "        #Compute Mean Feature\n",
        "        O4_mean = torch.mean(O4, 1, keepdim=False)\n",
        "\n",
        "        #Classifier MLP\n",
        "        out = self.LC1(O4_mean)\n",
        "        out = self.relu(out)\n",
        "        out = self.LC2(out)\n",
        "        return out        "
      ],
      "metadata": {
        "id": "dK429JCYIl4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Initialization edited from week 6 lab solutions\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear: # by checking type we can init different layers in different ways\n",
        "        torch.nn.init.kaiming_normal_(m.weight) #changed from normal_ to kaiming_normal_\n",
        "        torch.nn.init.zeros_(m.bias)"
      ],
      "metadata": {
        "id": "3BlzHGrKMVMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Model:\n",
        "num_inputs, num_hidden, num_patches, num_outputs = 49, 128, 16, 10\n",
        "net = Net(num_inputs, num_hidden, num_patches, num_outputs)\n",
        "net.apply(init_weights)"
      ],
      "metadata": {
        "id": "aEiO7_svMZAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Loss and Optimizer"
      ],
      "metadata": {
        "id": "Xk-Hq7T7K59C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross Entropy Loss:\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#learning rate and weight decay\n",
        "lr, wd = 0.1, 0.0005\n",
        "\n",
        "#SGD Optimizer\n",
        "optimizer = torch.optim.ASGD(net.parameters(), lr=lr, weight_decay=wd, lambd=0.0001, alpha=0.75, t0=1000000.0)"
      ],
      "metadata": {
        "id": "gTXOIGZQMoMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "QhA-9-McK_7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Script function mu.train_ch3 defined in my_utils_edit.py\n",
        "num_epochs = 100\n",
        "mu.train_ch3(net, train_iter, test_iter, loss, num_epochs, optimizer) #edited from my_utils.py file provided in week 3"
      ],
      "metadata": {
        "id": "74M7h3O2NEZb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper for Wikipedia Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import requests\n",
    "import bs4\n",
    "import lxml\n",
    "\n",
    "#Create List of Links to City Tables\n",
    "res = requests.get(\"https://en.wikipedia.org/wiki/List_of_towns_and_cities_with_100,000_or_more_inhabitants\")\n",
    "soup = bs4.BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "a_s = soup.findAll('a')\n",
    "\n",
    "\n",
    "pages = []\n",
    "\n",
    "for a in a_s:\n",
    "    href = a.get('href')\n",
    "    if 'List_of_towns_and_cities_with_100,000_or_more_inhabitants/country:_' in str(href) and href not in pages:\n",
    "        pages.append(href)\n",
    "\n",
    "#Create Separate Lists of City Names and Links to Cities\n",
    "cities = []\n",
    "city_names = []\n",
    "\n",
    "for page in pages:\n",
    "    link = 'https://en.wikipedia.org' + page\n",
    "\n",
    "    res = requests.get(link)\n",
    "    soup = bs4.BeautifulSoup(res.text, \"lxml\")\n",
    "    tables = soup.findAll('table')\n",
    "    \n",
    "    for table in tables:\n",
    "\n",
    "        tbody = table.find('tbody')\n",
    "        rows = tbody.findAll('tr')\n",
    "\n",
    "        for row in rows[1:]:\n",
    "            cell = row.find('td')\n",
    "            a = cell.find('a')\n",
    "            cities.append(a.get('href'))\n",
    "            city_names.append(a.get('title'))\n",
    "\n",
    "#Scrape All Text From Each City Page to List\n",
    "city_text = []\n",
    "\n",
    "for city in cities:\n",
    "    link = 'https://en.wikipedia.org' + city\n",
    "\n",
    "    res = requests.get(link)\n",
    "    soup = bs4.BeautifulSoup(res.text, \"lxml\")\n",
    "    body = soup.find('body')\n",
    "    \n",
    "    all_text = ''\n",
    "    for p in body.findAll('p'):\n",
    "        all_text += p.text\n",
    "        all_text = all_text.replace('\\n', '')\n",
    "        \n",
    "        chars_to_replace = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~0123456789'''\n",
    " \n",
    "        for char in chars_to_replace:\n",
    "            all_text = all_text.replace(char, \"\")\n",
    "            all_text = all_text.lower()\n",
    "        \n",
    "    city_text.append(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save scraped files\n",
    "import pickle\n",
    "\n",
    "with open('city_names', 'wb') as fp:\n",
    "    pickle.dump(city_names, fp)\n",
    "\n",
    "with open('city_text', 'wb') as fp:\n",
    "    pickle.dump(city_text, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsimonious Language Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries and Scraped City Names and Wikipedia Page Text\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from decimal import Decimal\n",
    "\n",
    "with open('city_names', 'rb') as fp:\n",
    "    city_names = pickle.load(fp)\n",
    "    \n",
    "with open('city_text', 'rb') as fp:\n",
    "    city_text = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find indices for UK cities over 100,000 population\n",
    "print(city_names.index(\"Basildon\"))\n",
    "print(city_names.index(\"Swansea\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basildon ˈbæzɪldən b\n",
      "swansea ˈswɒnzi wels\n"
     ]
    }
   ],
   "source": [
    "#Test that indices for names and text match\n",
    "print(city_text[3849][:20])\n",
    "print(city_text[3921][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create document collection\n",
    "uk_city_names = city_names[3849:3922]\n",
    "uk_city_text = city_text[3849:3922]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Collection Model\n",
    "def collection_probabilities(collection):\n",
    "        \n",
    "    collection = ' '.join(collection)\n",
    "    all_terms = set(collection.split())\n",
    "    \n",
    "    term_probs = []\n",
    "    for term in all_terms:\n",
    "        term_probs.append(collection.count(term) / len(collection))\n",
    "    \n",
    "    return all_terms, term_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign collection terms and collection term probabilities\n",
    "all_terms, term_probs = collection_probabilities(uk_city_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save collection terms and collection term probabilities\n",
    "with open('all_terms', 'wb') as fp:\n",
    "    pickle.dump(all_terms, fp)\n",
    "\n",
    "with open('term_probs', 'wb') as fp:\n",
    "    pickle.dump(term_probs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open collection terms and collection term probabilities\n",
    "with open('all_terms', 'rb') as fp:\n",
    "    city_names = pickle.load(fp)\n",
    "    \n",
    "with open('term_probs', 'rb') as fp:\n",
    "    city_text = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for collection terms and collection term probabilities\n",
    "col_prob_table = pd.DataFrame(all_terms, columns=['collection terms'])\n",
    "col_prob_table['collection probability'] = term_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe\n",
    "col_prob_table.to_pickle(\"col_prob_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open dataframe\n",
    "col_prob_table = pd.read_pickle(\"col_prob_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Apply Expectation Maximization Algorithm\n",
    "def expectation_maximization(document, all_terms, term_probs):\n",
    "    lam = 0.1\n",
    "    iterations = 10\n",
    "    \n",
    "    doc_probs = []\n",
    "    for term in all_terms:\n",
    "        doc_probs.append(document.count(term) / len(document))\n",
    "\n",
    "    #E-step\n",
    "    while iterations != 0:\n",
    "        e_t_values = []\n",
    "        for i in range(len(all_terms)):\n",
    "            e_t_values.append((doc_probs[i] * len(document)) * ((lam * doc_probs[i]) / \n",
    "                                                                ((1 - lam) * term_probs[i] + lam * doc_probs[i])))\n",
    "    #M-step\n",
    "        doc_probs = [(e_t / sum(e_t_values)) for e_t in e_t_values]\n",
    "        iterations -= 1\n",
    "        \n",
    "    for i in range(len(doc_probs)):\n",
    "        if doc_probs[i] < 0.0001:\n",
    "            doc_probs[i] = 0\n",
    "                \n",
    "    \n",
    "    return doc_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the EM function to index the document models parsimoniously\n",
    "for i in range(0, 73):\n",
    "    document = uk_city_text[i]\n",
    "    city_name = uk_city_names[i]\n",
    "    doc_probs = expectation_maximization(document, all_terms, term_probs)\n",
    "    \n",
    "    col_prob_table[city_name] = doc_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_table = col_prob_table.sort_values('collection probability', ascending=False)\n",
    "prob_table[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the index to collection terms to make it searchable\n",
    "prob_table = prob_table.set_index('collection terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe\n",
    "prob_table.to_pickle(\"prob_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open dataframe\n",
    "prob_table = pd.read_pickle(\"prob_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection probability</th>\n",
       "      <th>Basildon</th>\n",
       "      <th>Birmingham</th>\n",
       "      <th>Blackburn</th>\n",
       "      <th>Blackpool</th>\n",
       "      <th>Bolton</th>\n",
       "      <th>Bournemouth, Christchurch and Poole</th>\n",
       "      <th>Bradford</th>\n",
       "      <th>Brighton and Hove</th>\n",
       "      <th>Bristol</th>\n",
       "      <th>...</th>\n",
       "      <th>Worcester, England</th>\n",
       "      <th>York</th>\n",
       "      <th>Belfast</th>\n",
       "      <th>Aberdeen</th>\n",
       "      <th>Dundee</th>\n",
       "      <th>Edinburgh</th>\n",
       "      <th>Glasgow</th>\n",
       "      <th>Cardiff</th>\n",
       "      <th>Newport, Wales</th>\n",
       "      <th>Swansea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection terms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>basil</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.127294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basildon</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.126867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bas</th>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.063447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pitsea</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pits</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.022927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laindon</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vange</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essex</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billericay</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  collection probability  Basildon  Birmingham  Blackburn  \\\n",
       "collection terms                                                            \n",
       "basil                           0.000031  0.127294         0.0        0.0   \n",
       "basildon                        0.000028  0.126867         0.0        0.0   \n",
       "bas                             0.000287  0.063447         0.0        0.0   \n",
       "pitsea                          0.000006  0.028275         0.0        0.0   \n",
       "pits                            0.000009  0.026937         0.0        0.0   \n",
       "don                             0.000636  0.022927         0.0        0.0   \n",
       "laindon                         0.000003  0.015551         0.0        0.0   \n",
       "vange                           0.000007  0.009567         0.0        0.0   \n",
       "essex                           0.000033  0.008920         0.0        0.0   \n",
       "billericay                      0.000002  0.008483         0.0        0.0   \n",
       "\n",
       "                  Blackpool  Bolton  Bournemouth, Christchurch and Poole  \\\n",
       "collection terms                                                           \n",
       "basil                   0.0     0.0                                  0.0   \n",
       "basildon                0.0     0.0                                  0.0   \n",
       "bas                     0.0     0.0                                  0.0   \n",
       "pitsea                  0.0     0.0                                  0.0   \n",
       "pits                    0.0     0.0                                  0.0   \n",
       "don                     0.0     0.0                                  0.0   \n",
       "laindon                 0.0     0.0                                  0.0   \n",
       "vange                   0.0     0.0                                  0.0   \n",
       "essex                   0.0     0.0                                  0.0   \n",
       "billericay              0.0     0.0                                  0.0   \n",
       "\n",
       "                  Bradford  Brighton and Hove  Bristol  ...  \\\n",
       "collection terms                                        ...   \n",
       "basil                  0.0                0.0      0.0  ...   \n",
       "basildon               0.0                0.0      0.0  ...   \n",
       "bas                    0.0                0.0      0.0  ...   \n",
       "pitsea                 0.0                0.0      0.0  ...   \n",
       "pits                   0.0                0.0      0.0  ...   \n",
       "don                    0.0                0.0      0.0  ...   \n",
       "laindon                0.0                0.0      0.0  ...   \n",
       "vange                  0.0                0.0      0.0  ...   \n",
       "essex                  0.0                0.0      0.0  ...   \n",
       "billericay             0.0                0.0      0.0  ...   \n",
       "\n",
       "                  Worcester, England  York  Belfast  Aberdeen  Dundee  \\\n",
       "collection terms                                                        \n",
       "basil                            0.0   0.0      0.0       0.0     0.0   \n",
       "basildon                         0.0   0.0      0.0       0.0     0.0   \n",
       "bas                              0.0   0.0      0.0       0.0     0.0   \n",
       "pitsea                           0.0   0.0      0.0       0.0     0.0   \n",
       "pits                             0.0   0.0      0.0       0.0     0.0   \n",
       "don                              0.0   0.0      0.0       0.0     0.0   \n",
       "laindon                          0.0   0.0      0.0       0.0     0.0   \n",
       "vange                            0.0   0.0      0.0       0.0     0.0   \n",
       "essex                            0.0   0.0      0.0       0.0     0.0   \n",
       "billericay                       0.0   0.0      0.0       0.0     0.0   \n",
       "\n",
       "                  Edinburgh  Glasgow  Cardiff  Newport, Wales  Swansea  \n",
       "collection terms                                                        \n",
       "basil                   0.0      0.0      0.0             0.0      0.0  \n",
       "basildon                0.0      0.0      0.0             0.0      0.0  \n",
       "bas                     0.0      0.0      0.0             0.0      0.0  \n",
       "pitsea                  0.0      0.0      0.0             0.0      0.0  \n",
       "pits                    0.0      0.0      0.0             0.0      0.0  \n",
       "don                     0.0      0.0      0.0             0.0      0.0  \n",
       "laindon                 0.0      0.0      0.0             0.0      0.0  \n",
       "vange                   0.0      0.0      0.0             0.0      0.0  \n",
       "essex                   0.0      0.0      0.0             0.0      0.0  \n",
       "billericay              0.0      0.0      0.0             0.0      0.0  \n",
       "\n",
       "[10 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_table = prob_table.sort_values('Basildon', ascending=False)\n",
    "prob_table[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Results Using Unigram Model for Ranking Travel Destinations\n",
    "def parsimonious_search(probability_index_model, city_names, num_results):\n",
    "    query = input(\"Search: \").lower()\n",
    "    q_list = query.split()\n",
    "    \n",
    "    #Score calculator\n",
    "    lam = 0.9\n",
    "    city_score = []\n",
    "    for city in city_names[:-1]:\n",
    "        p = 1\n",
    "        #Unigram model with smoothing\n",
    "        for i in q_list:\n",
    "            p *= (1-lam) * prob_table.loc[i]['collection probability'] + lam * prob_table.loc[i][city]\n",
    "\n",
    "        city_score.append(p)\n",
    "    \n",
    "    \n",
    "    #Store and sort results\n",
    "    results = dict(zip(city_names[:-1], city_score))\n",
    "    results_sorted = dict(reversed(sorted(results.items(), key=lambda item: item[1])))\n",
    "    \n",
    "    #Print specified number of results\n",
    "    results_to_show = dict(itertools.islice(results_sorted.items(),num_results))\n",
    "    print('You should try visiting:')\n",
    "    for k, v in results_to_show.items():\n",
    "        print(f'{k}, it scored {Decimal(v):.2E}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: Seaside town with a castle\n",
      "You should try visiting:\n",
      "Newcastle upon Tyne, it scored 5.49E-18\n",
      "Blackpool, it scored 5.02E-18\n",
      "Bournemouth, Christchurch and Poole, it scored 2.41E-18\n",
      "Southend-on-Sea, it scored 9.77E-19\n",
      "Newport, Wales, it scored 1.47E-21\n"
     ]
    }
   ],
   "source": [
    "parsimonious_search(prob_table, uk_city_names, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
